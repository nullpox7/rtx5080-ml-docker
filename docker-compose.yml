version: '3.8'

services:
  gpu-ml-app:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: rtx5080-ml-container
    
    # GPU configuration for RTX5080
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    
    # Environment variables
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility,video
      - CUDA_VISIBLE_DEVICES=0
      - PYTHONPATH=/app
      - JUPYTER_ENABLE_LAB=yes
    
    # Volume mounts
    volumes:
      - ./src:/app/src
      - ./data:/app/data
      - ./models:/app/models
      - ./notebooks:/app/notebooks
      - ./outputs:/app/outputs
      - ~/.cache/pip:/root/.cache/pip  # pip cache
    
    # Port mappings
    ports:
      - "8888:8888"  # Jupyter Notebook
      - "6006:6006"  # TensorBoard
      - "8000:8000"  # FastAPI
    
    # Working directory
    working_dir: /app
    
    # Startup command (Jupyter)
    command: >
      sh -c "
        echo 'Starting RTX5080 GPU environment...' &&
        python -c 'import torch; print(f\"CUDA available: {torch.cuda.is_available()}\"); print(f\"GPU count: {torch.cuda.device_count()}\"); print(f\"GPU name: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\"}\")' &&
        jupyter notebook --ip=0.0.0.0 --port=8888 --no-browser --allow-root --NotebookApp.token='' --NotebookApp.password=''
      "
    
    # Restart policy
    restart: unless-stopped
    
    # Dependencies
    depends_on:
      - tensorboard
    
    # Network
    networks:
      - ml-network

  # TensorBoard service
  tensorboard:
    image: tensorflow/tensorflow:2.16.1-gpu
    container_name: tensorboard-service
    
    # GPU configuration
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    
    # Volume mounts
    volumes:
      - ./logs:/logs
      - ./models:/models
    
    # Port mapping
    ports:
      - "6006:6006"
    
    # Command
    command: tensorboard --logdir=/logs --host=0.0.0.0 --port=6006
    
    # Restart policy
    restart: unless-stopped
    
    # Network
    networks:
      - ml-network

# Network configuration
networks:
  ml-network:
    driver: bridge

# Volume configuration
volumes:
  pip-cache:
    driver: local
